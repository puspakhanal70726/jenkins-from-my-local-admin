Create a directory for the job definitions
mkdir -p $BUILD_ID/jobs

# Copy global configuration files into the workspace
cp $JENKINS_HOME/*.xml $BUILD_ID/

# Copy keys and secrets into the workspace
cp $JENKINS_HOME/identity.key.enc $BUILD_ID/
cp $JENKINS_HOME/secret.key $BUILD_ID/
cp $JENKINS_HOME/secret.key.not-so-secret $BUILD_ID/
cp -r $JENKINS_HOME/secrets $BUILD_ID/

# Copy user configuration files into the workspace
cp -r $JENKINS_HOME/users $BUILD_ID/

# Copy custom Pipeline workflow libraries
cp -r $JENKINS_HOME/workflow-libs $BUILD_ID

# Copy job definitions into the workspace
rsync -am --include='config.xml' --include='*/' --prune-empty-dirs --exclude='*' $JENKINS_HOME/jobs/ $BUILD_ID/jobs/

# Create an archive from all copied files (since the S3 plugin cannot copy folders recursively)
tar czf jenkins-configuration.tar.gz $BUILD_ID/

# Remove the directory so only the tar.gz gets copied to S3
rm -rf $BUILD_ID

#Deploy it to s3
#export AWS_DEFAULT_PROFILE=default
#sh 'export PATH=$PATH:/usr/bin; aws s3 cp /var/tmp/workspace/backup-${BUILD_NUMBER}.tar.gz s3://addgetemployeelab1/'

export AWS_DEFAULT_REGION="us-east-1"
export AWS_ACCESS_KEY_ID="AKIARTYSHQNYW"
export AWS_SECRET_ACCESS_KEY="TgMsp8o6ZR8okVG5bHtbA"

# Upload archive to S3
echo "Uploading archive to S3"
aws s3 cp jenkins-configuration.tar.gz s3://addgetemployeelab1/

# Remove tar.gz after it gets uploaded to S3
rm -rf jenkins-configuration.tar.gz
